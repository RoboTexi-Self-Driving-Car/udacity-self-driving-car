{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Compute the camera calibration matrix and distortion coefficients given a set of chessboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets import some libraries that we will use in the code.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets read the image paths from the file system.\n",
    "image_paths = glob('camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It may also help to visualize the images. Here we will visualize 5 random images from the list.\n",
    "np.random.seed(500)\n",
    "\n",
    "for i in np.random.randint(0, len(image_paths), 5):\n",
    "    img = mpimg.imread(image_paths[i])\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a helper function that handles the entire process of computing calibration parameters for a camera\n",
    "def CalibrateCameraDistortion(image_paths, nx=9, ny=6):\n",
    "    \n",
    "    obj = np.zeros((nx*ny, 3), np.float32)\n",
    "    obj[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1, 2)\n",
    "    \n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    \n",
    "    img = None\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        img = mpimg.imread(img_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        if ret==True:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(obj)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "    return ret, mtx, dist, rvecs, tvecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets use the images pointed by the elements of the list `image_paths` to compute camera calibration parameters\n",
    "num_corners_x, num_corners_y = 9, 6\n",
    "ret, mtx, dist, rvecs, tvecs = CalibrateCameraDistortion(image_paths, nx=num_corners_x, ny=num_corners_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use the computed camera calibration parameters for undistortion of the image\n",
    "rand_index = np.random.randint(0, len(image_paths))\n",
    "rand_img_path = image_paths[rand_index]\n",
    "\n",
    "img = mpimg.imread(rand_img_path)\n",
    "undist_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Also, lets visualize it to verify if the undistortion worked correctly\n",
    "plt.figure(figsize=(16,5))\n",
    "sub_plt_1 = plt.subplot(121)\n",
    "sub_plt_1.set_title(\"Original Image\")\n",
    "plt.imshow(img)\n",
    "\n",
    "sub_plt_2 = plt.subplot(122)\n",
    "sub_plt_2.set_title(\"Undistorted Image\")\n",
    "plt.imshow(undist_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, as mentioned in the project rubic, we will save the result on the file system for \n",
    "# visualization in the writeup\n",
    "\n",
    "if not os.path.exists(\"output_images/distortion_correction/\"):\n",
    "    os.makedirs(\"output_images/distortion_correction/\")\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_name = img_path[img_path.find(\"calibration\"):]\n",
    "    \n",
    "    img = mpimg.imread(img_path)\n",
    "    undist_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    cv2.imwrite(\"output_images/distortion_correction/\" + img_name, undist_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets write a simple pipeline to convert the orignal RGB image to a binary image that accentuates the lane lines\n",
    "def binary_img_pipe(image, gray_thresh=250, b_thresh=160):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    # Convert to LAB color space\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "    b_channel = lab[:, :, 2]\n",
    "    b_channel = (((b_channel - b_channel.min()) / b_channel.ptp()) * 255).astype(np.uint8)\n",
    "\n",
    "    combined_binary = np.zeros_like(gray)\n",
    "    combined_binary[(gray > gray_thresh) | (b_channel > b_thresh)] = 255\n",
    "    \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets read in a random image path from the test_images directory\n",
    "image_paths = glob('test_images/test*.jpg')\n",
    "rand_index = np.random.randint(0, len(image_paths))\n",
    "rand_img_path = image_paths[rand_index]\n",
    "\n",
    "# Now Lets read in the image to test the pipeline we designed\n",
    "image = mpimg.imread(rand_img_path)\n",
    "undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "binary_img = binary_img_pipe(undist_img)\n",
    "\n",
    "# Also, lets visualize it to verify if the pipeline worked correctly\n",
    "plt.figure(figsize=(16,5))\n",
    "sub_plt_1 = plt.subplot(121)\n",
    "sub_plt_1.set_title(\"Original Image\")\n",
    "plt.imshow(image)\n",
    "\n",
    "sub_plt_2 = plt.subplot(122)\n",
    "sub_plt_2.set_title(\"Binary Image\")\n",
    "plt.imshow(binary_img, \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, as mentioned in the project rubic, we will save the result on the file system for \n",
    "# visualization in the writeup\n",
    "\n",
    "if not os.path.exists(\"output_images/binary_img_pipe/\"):\n",
    "    os.makedirs(\"output_images/binary_img_pipe/\")\n",
    "    \n",
    "image_paths = glob('test_images/*.jpg')\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_name = img_path[img_path.find(\"test_images/\")+len(\"test_images/\"):]\n",
    "    \n",
    "    # Now Lets read in the image to test the pipeline we designed\n",
    "    image = mpimg.imread(img_path)\n",
    "    undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    binary_img = binary_img_pipe(undist_img)\n",
    "    \n",
    "    cv2.imwrite(\"output_images/binary_img_pipe/\" + img_name, binary_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perspective transform \n",
    "def perspective_transform(image, reverse=False):\n",
    "    imshape = image.shape\n",
    "    src = np.float32([[(200,680),(575, 455),(705, 455), (1100,680)]])\n",
    "    dst = np.float32([[350,720],[350,0],[950,0],[950,720]])\n",
    "#     src = np.float32([[(200,680),(505, 500),(790, 500), (1100,680)]])\n",
    "#     dst = np.float32([[200,680],[200,40],[1100,40],[1100,680]])\n",
    "    \n",
    "    # reverse - to get back the original image from birds-eye view, swap the points for perspective transform\n",
    "    if reverse:\n",
    "        M = cv2.getPerspectiveTransform(dst, src)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        \n",
    "    img_size = (imshape[1], imshape[0])\n",
    "    \n",
    "    return cv2.warpPerspective(image, M, img_size, flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(0, len(image_paths))\n",
    "rand_img_path = image_paths[rand_index]\n",
    "\n",
    "image = mpimg.imread(rand_img_path)\n",
    "undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "result = binary_img_pipe(undist_img)\n",
    "\n",
    "warped = perspective_transform(result, False)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(16,5))\n",
    "sub_plt_1 = plt.subplot(121)\n",
    "sub_plt_1.set_title(\"Binary Pipeline Image\")\n",
    "plt.imshow(result, \"gray\")\n",
    "\n",
    "sub_plt_2 = plt.subplot(122)\n",
    "sub_plt_2.set_title(\"Perspective Transform Image\")\n",
    "plt.imshow(warped, \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, as mentioned in the project rubic, we will save the result on the file system for \n",
    "# visualization in the writeup\n",
    "\n",
    "if not os.path.exists(\"output_images/perspective_transform/\"):\n",
    "    os.makedirs(\"output_images/perspective_transform/\")\n",
    "    \n",
    "image_paths = glob('test_images/*.jpg')\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_name = img_path[img_path.find(\"test_images/\")+len(\"test_images/\"):]\n",
    "    \n",
    "    # Now Lets read in the image to test the pipeline we designed\n",
    "    image = mpimg.imread(img_path)\n",
    "    undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    binary_img = binary_img_pipe(undist_img)\n",
    "    warped = perspective_transform(binary_img, False)\n",
    "    \n",
    "    cv2.imwrite(\"output_images/perspective_transform/\" + img_name, warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(image):\n",
    "    return np.sum(image[image.shape[0]//2:, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(0, len(image_paths))\n",
    "rand_img_path = image_paths[rand_index]\n",
    "\n",
    "image = mpimg.imread(rand_img_path)\n",
    "undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "result = binary_img_pipe(undist_img)\n",
    "\n",
    "warped = perspective_transform(result, False)\n",
    "\n",
    "histogram = hist(warped)\n",
    "plt.plot(histogram)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped, prev_left_fit, prev_right_fit):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = hist(binary_warped)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0] // 2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    # HYPERPARAMETERS\n",
    "    # number of sliding windows\n",
    "    nwindows = 9\n",
    "    # width of the windows +/- margin\n",
    "    margin = 80\n",
    "    # minimum number of pixels found to recenter window\n",
    "    minpix = 30\n",
    "    # height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0] // nwindows)\n",
    "    # x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped.shape[0] - window * window_height\n",
    "        # four  boundaries of the window\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    # concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # fit a second order polynomial\n",
    "    try:\n",
    "        if len(leftx) < 1000:\n",
    "            raise TypeError\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        prev_left_fit.append(left_fit)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if len(rightx) < 500:\n",
    "            raise TypeError\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        prev_right_fit.append(right_fit)\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    left_fit = np.empty((len(prev_left_fit), 3))\n",
    "    right_fit = np.empty((len(prev_right_fit), 3))\n",
    "\n",
    "    for i in range(len(prev_left_fit)):\n",
    "        left_fit[i] = np.array(prev_left_fit[i])\n",
    "\n",
    "    for i in range(len(prev_right_fit)):\n",
    "        right_fit[i] = np.array(prev_right_fit[i])\n",
    "\n",
    "    left_fit = left_fit.mean(axis=0)\n",
    "    right_fit = right_fit.mean(axis=0)\n",
    "\n",
    "    # generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "    # calc both polynomials using ploty, left_fit and right_fit\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    # create an image to draw on and an image to show the selection window\n",
    "    out_img = np.zeros([binary_warped.shape[0], binary_warped.shape[1], 3], np.uint8)\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    # new margin : mid of the left and right polynomial : polynomial for center of the lane\n",
    "    marginx = (right_fitx - left_fitx) / 2\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx + marginx, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx - marginx, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "    # draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0, 255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0, 255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    return result, left_fitx, right_fitx, ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, left_fitx, right_fitx, ploty = find_lane_pixels(warped, [], [])\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8,5))\n",
    "sub_plt_1 = plt.subplot(111)\n",
    "sub_plt_1.set_title(\"Lane Boundary Fit\")\n",
    "sub_plt_1.imshow(result)\n",
    "sub_plt_1.plot(left_fitx, ploty, color='yellow', linewidth=5)\n",
    "sub_plt_1.plot(right_fitx, ploty, color='yellow', linewidth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, as mentioned in the project rubic, we will save the result on the file system for \n",
    "# visualization in the writeup\n",
    "\n",
    "if not os.path.exists(\"output_images/lane_boundary_fit/\"):\n",
    "    os.makedirs(\"output_images/lane_boundary_fit/\")\n",
    "    \n",
    "image_paths = glob('test_images/*.jpg')\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_name = img_path[img_path.find(\"test_images/\")+len(\"test_images/\"):]\n",
    "    \n",
    "    # Now Lets read in the image to test the pipeline we designed\n",
    "    image = mpimg.imread(img_path)\n",
    "    undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    binary_img = binary_img_pipe(undist_img)\n",
    "    warped = perspective_transform(binary_img, False)\n",
    "    check = perspective_transform(result, True)\n",
    "    result, left_fitx, right_fitx, ploty = find_lane_pixels(warped, [], [])\n",
    "    \n",
    "    # Plot the result\n",
    "    plt.figure(figsize=(16,10))\n",
    "    sub_plt_1 = plt.subplot(111)\n",
    "    sub_plt_1.set_title(\"Lane Boundary Fit\")\n",
    "    sub_plt_1.imshow(result)\n",
    "    sub_plt_1.plot(left_fitx, ploty, color='yellow', linewidth=5)\n",
    "    sub_plt_1.plot(right_fitx, ploty, color='yellow', linewidth=5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"output_images/lane_boundary_fit/\" + img_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure radius of curvature\n",
    "def measure_curvature(image, leftx, rightx):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 25/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/550 # meters per pixel in x dimension\n",
    "    \n",
    "    ploty = np.linspace(0, 719, num=720)\n",
    "    \n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / (np.absolute(2*left_fit_cr[0]))  \n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / (np.absolute(2*right_fit_cr[0]))\n",
    "    \n",
    "    z = np.mean([left_curverad, right_curverad])\n",
    "    \n",
    "    cv2.putText(image,'Radius of Curvature: {0:.3f}(m)'.format(z), \n",
    "            (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the vehicle position wrt center of the lane\n",
    "def dst_from_center(image, left_fitx, right_fitx):\n",
    "    # find the x coordinate corresponding to the lane center\n",
    "    l = (left_fitx[-1] + right_fitx[-1])/2\n",
    "    \n",
    "    xm_per_pix = 3.7/550\n",
    "    \n",
    "    # calculate the offset i.e deviation of the lane center coordinate from the image center\n",
    "    # this will give the deviation of the vehicle from the center of the lane\n",
    "    dist = (image.shape[1]/2 - l) * xm_per_pix\n",
    "    \n",
    "    # dist is the offset: if the deviation is positive - the vehicle is left from the center of the lane \n",
    "    # if the distance is negative - the vehicle is right from the center of the lane \n",
    "    if dist <=0:\n",
    "        pos = 'left'\n",
    "    else:\n",
    "        pos = 'right'\n",
    "        \n",
    "    cv2.putText(image,\"Position: {0:.3f}(m) \".format(abs(dist)) + pos + \" of center.\", \n",
    "            (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_curvature(check, left_fitx, right_fitx)\n",
    "dst_from_center(check, left_fitx, right_fitx)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8,5))\n",
    "sub_plt_1 = plt.subplot(111)\n",
    "sub_plt_1.imshow(check)\n",
    "sub_plt_1.set_title('After calculating radius of curvature and vehicle position', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, left_fitx, right_fitx, ploty = find_lane_pixels(warped, [], [])\n",
    "check = perspective_transform(result, True)\n",
    "output = cv2.addWeighted(undist_img, 1, check, 1, 0)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, as mentioned in the project rubic, we will save the result on the file system for \n",
    "# visualization in the writeup\n",
    "\n",
    "if not os.path.exists(\"output_images/lane_boundary_overlay/\"):\n",
    "    os.makedirs(\"output_images/lane_boundary_overlay/\")\n",
    "    \n",
    "image_paths = glob('test_images/*.jpg')\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_name = img_path[img_path.find(\"test_images/\")+len(\"test_images/\"):]\n",
    "    \n",
    "    # Now Lets read in the image to test the pipeline we designed\n",
    "    image = mpimg.imread(img_path)\n",
    "    undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    binary_img = binary_img_pipe(undist_img)\n",
    "    warped = perspective_transform(binary_img, False)\n",
    "    result, left_fitx, right_fitx, ploty = find_lane_pixels(warped, [], [])\n",
    "    check = perspective_transform(result, True)\n",
    "    output = cv2.addWeighted(undist_img, 1, check, 1, 0)\n",
    "    \n",
    "    cv2.imwrite(\"output_images/lane_boundary_overlay/\" + img_name, output[:, :, [2, 1, 0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_curvature(output, left_fitx, right_fitx)\n",
    "dst_from_center(output, left_fitx, right_fitx)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Combine everything to define the lane detection pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneDetection(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.left_fit, self.right_fit = [], []\n",
    "        \n",
    "    def lane_detection(self, image):\n",
    "        # distortion correction\n",
    "        undist_img = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "\n",
    "        #calculate gradient\n",
    "        binary_img = binary_img_pipe(undist_img)\n",
    "\n",
    "        #perspective transform\n",
    "        warped_img = perspective_transform(binary_img, False)\n",
    "\n",
    "        #detect lane pixels \n",
    "        result, left_fitx, right_fitx, ploty = find_lane_pixels(warped_img, self.left_fit, self.right_fit)\n",
    "\n",
    "        if len(self.left_fit) > 15:\n",
    "            self.left_fit.pop(0)\n",
    "\n",
    "        if len(self.right_fit) > 15:\n",
    "            self.right_fit.pop(0)\n",
    "\n",
    "        #reverse perspective\n",
    "        check = perspective_transform(result, True)\n",
    "\n",
    "        #wrap to the original image\n",
    "        output = cv2.addWeighted(undist_img, 1, check, 1, 0)\n",
    "\n",
    "        #measure radius of curvature and distance from the center\n",
    "        measure_curvature(output, left_fitx, right_fitx)\n",
    "        dst_from_center(output, left_fitx, right_fitx)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"output_images/final_LD/\"):\n",
    "    os.makedirs(\"output_images/final_LD/\")\n",
    "\n",
    "# Now lets read the image paths from the file system.\n",
    "image_paths = glob('test_images/*.jpg')\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img_name = img_path[img_path.find(\"test_images/\")+len(\"test_images/\"):]\n",
    "    image = mpimg.imread(img_path)\n",
    "    ld = LaneDetection()\n",
    "    ld_output = ld.lane_detection(image)\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.imshow(ld_output)\n",
    "    \n",
    "    cv2.imwrite(\"output_images/final_LD/\" + img_name, ld_output[:, :, [2, 1, 0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Finally, test the Lane Detection Pipeline on the test Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import imageio\n",
    "# imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_output = 'output_videos/project_video.mp4'\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "ld = LaneDetection()\n",
    "white_clip = clip1.fl_image(ld.lane_detection)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
